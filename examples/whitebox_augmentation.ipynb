{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d67e1bf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Whitebox augmentation demo\n",
    "\n",
    "We use a MAITE image-classification `Augmentation` to represent a simple\n",
    "adversarial attack on model input data. Because the attack depends on\n",
    "gradient information that is not guaranteed to be available for MAITE\n",
    "`Model` objects, we must get the information in an application-specific\n",
    "way. In this case, we write the `Augmentation` implementer class such that\n",
    "it has access to the underlying (framework-specific) model. This way, the\n",
    "`Augmentation` implementer can access model gradients internally within its\n",
    "`__call__` method and after construction the implementer can be treated as\n",
    "any other implementer of `Augmentation`.\n",
    "\n",
    "In this example, we consider the image classification domain\n",
    "where input and targets from the a prediction model are both tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6adff9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf07f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations  # permit use of tuple/dict as generic typehints in 3.8\n",
    "\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Protocol, Sequence, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from maite.protocols import ArrayLike\n",
    "from maite.protocols.image_classification import Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c9d1db",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Define a simple protocol for a broad set of attacks\n",
    "This isn't strictly necessary, but helpful for extensibility.\n",
    "\n",
    "Any interface expecting an instance of this protocol class will be\n",
    "able to handle any implementer (structural subtype), so implementations\n",
    "of attacks can be modified/rewritten without modifying classes\n",
    "that are expected to use those objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "739f59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifierAttack(Protocol):\n",
    "    \"\"\"\n",
    "    Protocol defining an interface that might be satisfied by an attack on an\n",
    "    image classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        input_batch: torch.Tensor,\n",
    "        target_batch: torch.Tensor,\n",
    "    ) -> torch.Tensor: ...\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80211c36",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Define a simple implementer of above protocol class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9d9a23",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DumbAttack:\n",
    "    \"\"\"\n",
    "    Very basic implementer of above ImageClassifierAttack protocol\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        input_batch: ArrayLike,\n",
    "        target_batch: ArrayLike,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Given a torch model, a model input batch, and a model target batch\n",
    "        (i.e. ground truth) calculate an adversarial perturbation that can be\n",
    "        added to the input tensor to form an adversarial input.\n",
    "        \"\"\"\n",
    "\n",
    "        # type-narrow inputs to type tensor\n",
    "        input_batch_tn = torch.as_tensor(input_batch)\n",
    "        input_batch_tn.requires_grad = True\n",
    "\n",
    "        # type-narrow Targets to type tensor\n",
    "        target_batch_tn = torch.as_tensor(target_batch)\n",
    "\n",
    "        preds = model(input_batch_tn)\n",
    "\n",
    "        # calculate some simple loss\n",
    "        loss = torch.sum(\n",
    "            torch.nn.functional.binary_cross_entropy(preds, target_batch_tn)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        assert input_batch_tn.grad is not None\n",
    "\n",
    "        return input_batch_tn.grad * 1e-4\n",
    "\n",
    "\n",
    "# TODO: Try to demonstrate a standard approach to implement protocols that permit\n",
    "#       structural subclass checks at that class object level (i.e. using\n",
    "#       \"issubclass(SomeUserClass, SomeProtocol)\" and dont require instantiation.\n",
    "#       (i.e. isinstance(SomeUserClass(...), SomeProtocol). Otherwise, introspection\n",
    "#       and inference tools wont be able to verify protocol compatibility without\n",
    "#       instantiating. This inferrence ability is a huge potential gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12a230b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Define a \"whitebox augmentation\" class\n",
    "The class will store framework-specific model while implementing MAITE\n",
    "`Augmentation` protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae531a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Augmentation that takes anything satisfying this ImageClassifierAttack\n",
    "# object in its constructor and uses it within its __call__ method. After it is\n",
    "# constructed, the user can treat it like any other implementer of the Augmentation\n",
    "# protocol.\n",
    "class WhiteboxAugmentation:\n",
    "    \"\"\"\n",
    "    Apply an image classifier attack\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: torch.nn.Module, attack: ImageClassifierAttack):\n",
    "        # store torch model as an attribute specific to this augmentation\n",
    "        self.attack = attack\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(\n",
    "        self, datum: tuple[ArrayLike, ArrayLike, Sequence[dict[str, Any]]]\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor, Sequence[dict[str, Any]]]:\n",
    "        # unpack tuple input\n",
    "        input_batch, target_batch, metadata_batch = datum\n",
    "\n",
    "        # type-narrow inputs to type tensor\n",
    "        input_batch_tn = torch.as_tensor(input_batch)\n",
    "\n",
    "        # type-narrow Targets to type tensor\n",
    "        target_batch_tn = torch.as_tensor(target_batch)\n",
    "\n",
    "        attack_perturbation = self.attack(self.model, input_batch_tn, target_batch_tn)\n",
    "        input_batch_aug = input_batch_tn + attack_perturbation\n",
    "\n",
    "        # Modify returned metadata object to record any important\n",
    "        # aspects of this augmentation\n",
    "        metadata_batch_aug = copy.deepcopy(metadata_batch)\n",
    "        for i, datum_metadata in enumerate(metadata_batch_aug):\n",
    "            if \"aug_applied\" not in datum_metadata.keys():\n",
    "                datum_metadata[\"augs_applied\"] = list()\n",
    "\n",
    "                datum_metadata[\"augs_applied\"].append(\n",
    "                    {\n",
    "                        \"name\": self.attack.name,\n",
    "                        \"mean_perturbation\": torch.mean(attack_perturbation[i]).numpy(),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        return (input_batch_aug, target_batch_tn, metadata_batch_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed183ed",
   "metadata": {},
   "source": [
    "## Test the augmentation\n",
    "Create dummy torch module and batch of input/target/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a66a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummy model that takes Nx5 inputs and produces a onehot\n",
    "# vector of pseudoprobabilities\n",
    "BATCH_SIZE = 4\n",
    "H_IMG = 32\n",
    "W_IMG = 32\n",
    "C_IMG = 3\n",
    "N_CLASSES = 5\n",
    "\n",
    "dummy_model = nn.Sequential(\n",
    "    nn.Flatten(), nn.Linear(H_IMG * W_IMG * C_IMG, N_CLASSES), nn.ReLU(), nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82336b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/je24578/miniconda3/envs/maite_inc3_demo/lib/python3.8/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Apply a WhiteboxAugmentation to a batch\n",
    "\n",
    "\n",
    "# create instance of WhiteboxAugmentation class\n",
    "wb_aug: Augmentation = WhiteboxAugmentation(\n",
    "    model=dummy_model, attack=DumbAttack(name=\"silly_attack\")\n",
    ")\n",
    "\n",
    "# create a 'dummy' datum batch\n",
    "datum_batch: Tuple[torch.Tensor, torch.Tensor, Sequence[dict[str, Any]]] = (\n",
    "    torch.rand((BATCH_SIZE, C_IMG, H_IMG, W_IMG)),\n",
    "    torch.eye(BATCH_SIZE, N_CLASSES),\n",
    "    [dict() for _ in range(BATCH_SIZE)],\n",
    ")\n",
    "\n",
    "# apply augmentation\n",
    "datum_batch_aug = wb_aug(datum_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c38b2",
   "metadata": {},
   "source": [
    "## Print result of augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e2815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of augmentation (by datum)\n",
      "model input:\n",
      " tensor([[[0.7955, 0.1129, 0.7171,  ..., 0.2297, 0.3298, 0.5357],\n",
      "         [0.7627, 0.5773, 0.6534,  ..., 0.8270, 0.6301, 0.5393],\n",
      "         [0.0184, 0.2435, 0.0479,  ..., 0.8979, 0.2758, 0.5878],\n",
      "         ...,\n",
      "         [0.8196, 0.1781, 0.7873,  ..., 0.7249, 0.6869, 0.3866],\n",
      "         [0.5243, 0.5222, 0.8653,  ..., 0.6402, 0.3306, 0.8031],\n",
      "         [0.6204, 0.8290, 0.3151,  ..., 0.4511, 0.1459, 0.0962]],\n",
      "\n",
      "        [[0.4418, 0.5967, 0.4572,  ..., 0.6024, 0.8852, 0.1500],\n",
      "         [0.6860, 0.2836, 0.1049,  ..., 0.8003, 0.4525, 0.5554],\n",
      "         [0.9274, 0.4137, 0.9634,  ..., 0.0191, 0.0723, 0.2648],\n",
      "         ...,\n",
      "         [0.5196, 0.3777, 0.3172,  ..., 0.9507, 0.9359, 0.0495],\n",
      "         [0.5860, 0.4772, 0.5473,  ..., 0.3217, 0.1889, 0.0311],\n",
      "         [0.5033, 0.2301, 0.1392,  ..., 0.2666, 0.1249, 0.5137]],\n",
      "\n",
      "        [[0.1291, 0.7575, 0.9652,  ..., 0.4392, 0.9244, 0.2767],\n",
      "         [0.3489, 0.8987, 0.5955,  ..., 0.4570, 0.4043, 0.5867],\n",
      "         [0.3754, 0.0782, 0.9733,  ..., 0.0558, 0.5715, 0.1705],\n",
      "         ...,\n",
      "         [0.4040, 0.6233, 0.7880,  ..., 0.5884, 0.2832, 0.8144],\n",
      "         [0.5886, 0.8138, 0.5437,  ..., 0.3337, 0.4174, 0.6560],\n",
      "         [0.6221, 0.5817, 0.2006,  ..., 0.4826, 0.4778, 0.0408]]],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "model input (augmented):\n",
      " tensor([[[0.7955, 0.1129, 0.7171,  ..., 0.2297, 0.3298, 0.5357],\n",
      "         [0.7627, 0.5773, 0.6534,  ..., 0.8270, 0.6301, 0.5393],\n",
      "         [0.0184, 0.2435, 0.0479,  ..., 0.8979, 0.2758, 0.5878],\n",
      "         ...,\n",
      "         [0.8196, 0.1781, 0.7873,  ..., 0.7249, 0.6869, 0.3866],\n",
      "         [0.5243, 0.5222, 0.8653,  ..., 0.6402, 0.3306, 0.8031],\n",
      "         [0.6204, 0.8290, 0.3151,  ..., 0.4511, 0.1459, 0.0962]],\n",
      "\n",
      "        [[0.4418, 0.5967, 0.4572,  ..., 0.6024, 0.8852, 0.1500],\n",
      "         [0.6860, 0.2836, 0.1049,  ..., 0.8003, 0.4525, 0.5554],\n",
      "         [0.9274, 0.4137, 0.9634,  ..., 0.0191, 0.0723, 0.2648],\n",
      "         ...,\n",
      "         [0.5196, 0.3777, 0.3172,  ..., 0.9507, 0.9359, 0.0495],\n",
      "         [0.5860, 0.4772, 0.5473,  ..., 0.3217, 0.1889, 0.0311],\n",
      "         [0.5033, 0.2301, 0.1392,  ..., 0.2666, 0.1249, 0.5137]],\n",
      "\n",
      "        [[0.1291, 0.7575, 0.9652,  ..., 0.4392, 0.9244, 0.2767],\n",
      "         [0.3489, 0.8987, 0.5955,  ..., 0.4570, 0.4043, 0.5867],\n",
      "         [0.3754, 0.0782, 0.9733,  ..., 0.0558, 0.5715, 0.1705],\n",
      "         ...,\n",
      "         [0.4040, 0.6233, 0.7880,  ..., 0.5884, 0.2832, 0.8144],\n",
      "         [0.5886, 0.8138, 0.5437,  ..., 0.3337, 0.4174, 0.6560],\n",
      "         [0.6221, 0.5817, 0.2006,  ..., 0.4826, 0.4778, 0.0408]]],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "datum metadata:\n",
      " {'augs_applied': [{'name': 'silly_attack', 'mean_perturbation': array(2.6005545e-10, dtype=float32)}]}\n",
      "\n",
      "\n",
      "model input:\n",
      " tensor([[[0.7277, 0.0610, 0.4459,  ..., 0.1324, 0.6931, 0.4831],\n",
      "         [0.3357, 0.2598, 0.9151,  ..., 0.9587, 0.3670, 0.0424],\n",
      "         [0.2254, 0.5611, 0.5898,  ..., 0.8847, 0.2672, 0.3367],\n",
      "         ...,\n",
      "         [0.1655, 0.0468, 0.2973,  ..., 0.5467, 0.2152, 0.2969],\n",
      "         [0.7807, 0.5768, 0.8717,  ..., 0.7655, 0.7925, 0.7031],\n",
      "         [0.2495, 0.1374, 0.9792,  ..., 0.1666, 0.0787, 0.4178]],\n",
      "\n",
      "        [[0.5573, 0.9301, 0.2150,  ..., 0.0273, 0.0702, 0.2907],\n",
      "         [0.4828, 0.9436, 0.6980,  ..., 0.5631, 0.9776, 0.1511],\n",
      "         [0.3825, 0.7927, 0.1534,  ..., 0.2219, 0.5138, 0.0942],\n",
      "         ...,\n",
      "         [0.2905, 0.0979, 0.4517,  ..., 0.8797, 0.1247, 0.8100],\n",
      "         [0.9624, 0.5394, 0.4569,  ..., 0.9570, 0.8962, 0.6888],\n",
      "         [0.2826, 0.2760, 0.3608,  ..., 0.5237, 0.3786, 0.6412]],\n",
      "\n",
      "        [[0.4269, 0.4669, 0.7159,  ..., 0.1097, 0.5974, 0.5621],\n",
      "         [0.8011, 0.7773, 0.0157,  ..., 0.8682, 0.9831, 0.3359],\n",
      "         [0.5685, 0.6629, 0.5850,  ..., 0.5571, 0.5502, 0.9438],\n",
      "         ...,\n",
      "         [0.4440, 0.5309, 0.8891,  ..., 0.9712, 0.3909, 0.4144],\n",
      "         [0.3643, 0.5297, 0.8256,  ..., 0.7872, 0.9976, 0.3150],\n",
      "         [0.1153, 0.0101, 0.7896,  ..., 0.9691, 0.8292, 0.7878]]],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "model input (augmented):\n",
      " tensor([[[0.7277, 0.0610, 0.4459,  ..., 0.1324, 0.6931, 0.4831],\n",
      "         [0.3357, 0.2598, 0.9151,  ..., 0.9587, 0.3670, 0.0424],\n",
      "         [0.2254, 0.5611, 0.5898,  ..., 0.8847, 0.2672, 0.3367],\n",
      "         ...,\n",
      "         [0.1655, 0.0468, 0.2973,  ..., 0.5467, 0.2152, 0.2969],\n",
      "         [0.7807, 0.5768, 0.8717,  ..., 0.7655, 0.7925, 0.7031],\n",
      "         [0.2495, 0.1374, 0.9792,  ..., 0.1666, 0.0787, 0.4178]],\n",
      "\n",
      "        [[0.5573, 0.9301, 0.2150,  ..., 0.0273, 0.0702, 0.2907],\n",
      "         [0.4828, 0.9436, 0.6980,  ..., 0.5631, 0.9776, 0.1511],\n",
      "         [0.3825, 0.7927, 0.1534,  ..., 0.2219, 0.5138, 0.0942],\n",
      "         ...,\n",
      "         [0.2905, 0.0979, 0.4517,  ..., 0.8797, 0.1247, 0.8100],\n",
      "         [0.9624, 0.5394, 0.4569,  ..., 0.9570, 0.8962, 0.6888],\n",
      "         [0.2826, 0.2760, 0.3608,  ..., 0.5237, 0.3786, 0.6412]],\n",
      "\n",
      "        [[0.4269, 0.4669, 0.7159,  ..., 0.1097, 0.5974, 0.5621],\n",
      "         [0.8011, 0.7773, 0.0157,  ..., 0.8682, 0.9831, 0.3359],\n",
      "         [0.5685, 0.6629, 0.5850,  ..., 0.5571, 0.5502, 0.9438],\n",
      "         ...,\n",
      "         [0.4440, 0.5309, 0.8891,  ..., 0.9712, 0.3909, 0.4144],\n",
      "         [0.3643, 0.5297, 0.8256,  ..., 0.7872, 0.9976, 0.3150],\n",
      "         [0.1153, 0.0101, 0.7896,  ..., 0.9691, 0.8292, 0.7878]]],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "datum metadata:\n",
      " {'augs_applied': [{'name': 'silly_attack', 'mean_perturbation': array(2.9346478e-10, dtype=float32)}]}\n",
      "\n",
      "\n",
      "model input:\n",
      " tensor([[[0.3215, 0.3514, 0.6150,  ..., 0.0464, 0.9686, 0.4174],\n",
      "         [0.2049, 0.6631, 0.5133,  ..., 0.9067, 0.4698, 0.8191],\n",
      "         [0.1059, 0.6169, 0.1335,  ..., 0.3241, 0.9833, 0.0820],\n",
      "         ...,\n",
      "         [0.7705, 0.9557, 0.4421,  ..., 0.7057, 0.6876, 0.6830],\n",
      "         [0.3403, 0.4786, 0.9493,  ..., 0.3600, 0.6193, 0.4190],\n",
      "         [0.8460, 0.9409, 0.1793,  ..., 0.6097, 0.6413, 0.4632]],\n",
      "\n",
      "        [[0.8922, 0.6042, 0.6248,  ..., 0.8873, 0.6403, 0.1657],\n",
      "         [0.9394, 0.7678, 0.8027,  ..., 0.8331, 0.6901, 0.1098],\n",
      "         [0.6562, 0.8712, 0.3931,  ..., 0.3762, 0.4917, 0.9832],\n",
      "         ...,\n",
      "         [0.0321, 0.5785, 0.2810,  ..., 0.6771, 0.7697, 0.5714],\n",
      "         [0.0875, 0.9103, 0.5798,  ..., 0.1686, 0.3537, 0.9398],\n",
      "         [0.6955, 0.3851, 0.8973,  ..., 0.5673, 0.5829, 0.2882]],\n",
      "\n",
      "        [[0.4331, 0.7302, 0.0644,  ..., 0.3657, 0.4165, 0.3022],\n",
      "         [0.1675, 0.7033, 0.5647,  ..., 0.8744, 0.1913, 0.8836],\n",
      "         [0.8531, 0.7951, 0.6087,  ..., 0.0199, 0.1960, 0.6232],\n",
      "         ...,\n",
      "         [0.6967, 0.4255, 0.6626,  ..., 0.5357, 0.0686, 0.6605],\n",
      "         [0.9059, 0.1241, 0.2512,  ..., 0.3948, 0.5777, 0.7301],\n",
      "         [0.9752, 0.5218, 0.1108,  ..., 0.6474, 0.6285, 0.9239]]],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "model input (augmented):\n",
      " tensor([[[0.3215, 0.3514, 0.6150,  ..., 0.0464, 0.9686, 0.4174],\n",
      "         [0.2049, 0.6631, 0.5133,  ..., 0.9067, 0.4698, 0.8191],\n",
      "         [0.1059, 0.6169, 0.1335,  ..., 0.3241, 0.9833, 0.0820],\n",
      "         ...,\n",
      "         [0.7705, 0.9557, 0.4421,  ..., 0.7057, 0.6876, 0.6830],\n",
      "         [0.3403, 0.4786, 0.9493,  ..., 0.3600, 0.6193, 0.4190],\n",
      "         [0.8460, 0.9409, 0.1793,  ..., 0.6097, 0.6413, 0.4632]],\n",
      "\n",
      "        [[0.8922, 0.6042, 0.6248,  ..., 0.8873, 0.6403, 0.1657],\n",
      "         [0.9394, 0.7678, 0.8027,  ..., 0.8331, 0.6901, 0.1098],\n",
      "         [0.6562, 0.8712, 0.3931,  ..., 0.3762, 0.4917, 0.9832],\n",
      "         ...,\n",
      "         [0.0321, 0.5785, 0.2810,  ..., 0.6771, 0.7697, 0.5714],\n",
      "         [0.0875, 0.9103, 0.5798,  ..., 0.1686, 0.3537, 0.9398],\n",
      "         [0.6955, 0.3851, 0.8973,  ..., 0.5673, 0.5829, 0.2882]],\n",
      "\n",
      "        [[0.4331, 0.7302, 0.0644,  ..., 0.3657, 0.4165, 0.3022],\n",
      "         [0.1675, 0.7033, 0.5647,  ..., 0.8744, 0.1913, 0.8836],\n",
      "         [0.8531, 0.7951, 0.6087,  ..., 0.0199, 0.1960, 0.6232],\n",
      "         ...,\n",
      "         [0.6967, 0.4255, 0.6626,  ..., 0.5357, 0.0686, 0.6605],\n",
      "         [0.9059, 0.1241, 0.2512,  ..., 0.3948, 0.5777, 0.7301],\n",
      "         [0.9752, 0.5218, 0.1108,  ..., 0.6474, 0.6285, 0.9239]]],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "datum metadata:\n",
      " {'augs_applied': [{'name': 'silly_attack', 'mean_perturbation': array(-1.1591631e-10, dtype=float32)}]}\n",
      "\n",
      "\n",
      "model input:\n",
      " tensor([[[0.1808, 0.7116, 0.5259,  ..., 0.8416, 0.6823, 0.2724],\n",
      "         [0.7531, 0.4537, 0.6223,  ..., 0.3243, 0.2375, 0.1156],\n",
      "         [0.3605, 0.7853, 0.4687,  ..., 0.4771, 0.9331, 0.8376],\n",
      "         ...,\n",
      "         [0.7611, 0.0889, 0.3243,  ..., 0.5618, 0.3160, 0.8769],\n",
      "         [0.7491, 0.4390, 0.7050,  ..., 0.3390, 0.6713, 0.0014],\n",
      "         [0.9425, 0.8580, 0.9505,  ..., 0.9293, 0.2654, 0.0693]],\n",
      "\n",
      "        [[0.2513, 0.8553, 0.2987,  ..., 0.3069, 0.0834, 0.4075],\n",
      "         [0.0984, 0.6887, 0.4704,  ..., 0.9124, 0.6616, 0.9415],\n",
      "         [0.3547, 0.0325, 0.8473,  ..., 0.5192, 0.3485, 0.0983],\n",
      "         ...,\n",
      "         [0.6620, 0.3379, 0.2376,  ..., 0.0296, 0.9658, 0.1861],\n",
      "         [0.6025, 0.9431, 0.3255,  ..., 0.3747, 0.1874, 0.3511],\n",
      "         [0.2619, 0.3472, 0.7377,  ..., 0.5365, 0.0929, 0.8219]],\n",
      "\n",
      "        [[0.7229, 0.7156, 0.2168,  ..., 0.4810, 0.5704, 0.6975],\n",
      "         [0.4456, 0.2433, 0.9206,  ..., 0.4638, 0.4802, 0.1012],\n",
      "         [0.5309, 0.0137, 0.2842,  ..., 0.8487, 0.1674, 0.9976],\n",
      "         ...,\n",
      "         [0.0690, 0.0896, 0.2024,  ..., 0.5803, 0.6212, 0.8785],\n",
      "         [0.1385, 0.6529, 0.0348,  ..., 0.8554, 0.0016, 0.4474],\n",
      "         [0.3623, 0.2975, 0.9666,  ..., 0.4292, 0.8719, 0.4548]]],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "model input (augmented):\n",
      " tensor([[[0.1808, 0.7116, 0.5259,  ..., 0.8416, 0.6823, 0.2724],\n",
      "         [0.7531, 0.4537, 0.6223,  ..., 0.3243, 0.2375, 0.1156],\n",
      "         [0.3605, 0.7853, 0.4687,  ..., 0.4771, 0.9331, 0.8376],\n",
      "         ...,\n",
      "         [0.7611, 0.0889, 0.3243,  ..., 0.5618, 0.3160, 0.8769],\n",
      "         [0.7491, 0.4390, 0.7050,  ..., 0.3390, 0.6713, 0.0014],\n",
      "         [0.9425, 0.8580, 0.9505,  ..., 0.9293, 0.2654, 0.0693]],\n",
      "\n",
      "        [[0.2513, 0.8553, 0.2987,  ..., 0.3069, 0.0834, 0.4075],\n",
      "         [0.0984, 0.6887, 0.4704,  ..., 0.9124, 0.6616, 0.9415],\n",
      "         [0.3547, 0.0325, 0.8473,  ..., 0.5192, 0.3485, 0.0983],\n",
      "         ...,\n",
      "         [0.6620, 0.3379, 0.2376,  ..., 0.0296, 0.9658, 0.1861],\n",
      "         [0.6025, 0.9431, 0.3255,  ..., 0.3747, 0.1874, 0.3511],\n",
      "         [0.2619, 0.3472, 0.7377,  ..., 0.5365, 0.0929, 0.8219]],\n",
      "\n",
      "        [[0.7229, 0.7156, 0.2168,  ..., 0.4810, 0.5704, 0.6975],\n",
      "         [0.4456, 0.2433, 0.9206,  ..., 0.4638, 0.4802, 0.1012],\n",
      "         [0.5309, 0.0137, 0.2842,  ..., 0.8487, 0.1674, 0.9976],\n",
      "         ...,\n",
      "         [0.0690, 0.0896, 0.2024,  ..., 0.5803, 0.6212, 0.8785],\n",
      "         [0.1385, 0.6529, 0.0348,  ..., 0.8554, 0.0016, 0.4474],\n",
      "         [0.3623, 0.2975, 0.9666,  ..., 0.4292, 0.8719, 0.4548]]],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "datum metadata:\n",
      " {'augs_applied': [{'name': 'silly_attack', 'mean_perturbation': array(-6.8335816e-11, dtype=float32)}]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpack datums\n",
    "# TODO: consider whether tuple of iterables or iterable of tuples is more convenient\n",
    "#       as a batch format. Tuple of iterables seems to require below unpacking\n",
    "\n",
    "model_input_batch_aug, model_target_batch_aug, md_batch_aug = datum_batch_aug\n",
    "model_input_batch, model_target_batch, md_batch = datum_batch\n",
    "\n",
    "print(\"Results of augmentation (by datum)\")\n",
    "for model_input_aug, model_target_aug, md_aug, model_input, model_target, md in zip(\n",
    "    model_input_batch_aug,\n",
    "    model_target_batch_aug,\n",
    "    md_batch_aug,\n",
    "    model_input_batch,\n",
    "    model_target_batch,\n",
    "    md_batch,\n",
    "):\n",
    "    print(f\"model input:\\n {model_input}\")\n",
    "    print(f\"model input (augmented):\\n {model_input_aug}\")\n",
    "    print(f\"datum metadata:\\n {md_aug}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "maite_inc3_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
