{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2024, MASSACHUSETTS INSTITUTE OF TECHNOLOGY<br/>\n",
    "Subject to FAR 52.227-11 – Patent Rights – Ownership by the Contractor (May 2014).<br/>\n",
    "SPDX-License-Identifier: MIT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of MAITE Protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAITE provides protocols for the following AI components:\n",
    "\n",
    "* models\n",
    "* datasets\n",
    "* dataloaders\n",
    "* augmentations\n",
    "* metrics\n",
    "\n",
    " MAITE protocols specify expected interfaces of these components (i.e, a minimal set of required attributes, methods, and method type signatures) to promote interoperability in test and evaluation (T&E). This enables the creation of higher-level workflows (e.g., an `evaluate` utility) that can interact with any components that conform to the protocols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Concept: Bridging ArrayLikes\n",
    "\n",
    "MAITE defines a protocol called `ArrayLike` (inspired by NumPy's [interoperability approach](https://numpy.org/devdocs/user/basics.interoperability.html)) that helps components that natively use different flavors of tensors (e.g., NumPy ndarray, PyTorch Tensor, JAX ndarray) work together.\n",
    "\n",
    "In this example, the functions \"type narrow\" from `ArrayLike` to the type they want to work with internally. Note that this doesn't necessarily require a conversion depending on the actual input type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from maite.protocols import ArrayLike\n",
    "\n",
    "def my_numpy_fn(x: ArrayLike) -> np.ndarray:\n",
    "    arr = np.asarray(x)\n",
    "    # ...\n",
    "    return arr\n",
    "\n",
    "def my_torch_fn(x: ArrayLike) -> torch.Tensor:\n",
    "    tensor = torch.as_tensor(x)\n",
    "    # ...\n",
    "    return tensor\n",
    "\n",
    "# can apply NumPy function to PyTorch Tensor\n",
    "np_out = my_numpy_fn(torch.rand(2, 3))\n",
    "\n",
    "# can apply PyTorch function to NumPy array\n",
    "torch_out = my_torch_fn(np.random.rand(2, 3))\n",
    "\n",
    "# note: no performance hit from conversion when all `ArrayLike`s are from same library\n",
    "# or when can share the same underlying memory\n",
    "torch_out = my_torch_fn(torch.rand(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using bridging, we MAITE can permit implementers of the protocol to internally interact with their own types while exposing a more open interface to other MAITE-compliant components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Types\n",
    "\n",
    "MAITE represents an *individual* data item as a tuple of:\n",
    "\n",
    "* input (i.e., image),\n",
    "* target (i.e., label), and\n",
    "* metadata (at the datum level)\n",
    "\n",
    "and a *batch* of data items as a tuple of:\n",
    "\n",
    "* input batches,\n",
    "* target batches, and\n",
    "* metadata batches.\n",
    "\n",
    "MAITE provides versions of `Model`, `Dataset`, `DataLoader`, `Augmentation`, and `Metric` protocols that correspond to different machine learning tasks (e.g. image classification, object detection) by parameterizing protocol interfaces on the particular input, target, and metadata types associated with that task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Image Classification\n",
    "\n",
    "For image classification with `Cl` image classes, we have:\n",
    "\n",
    "```python\n",
    "# define type to store an id of each datum (additional fields can be added by defining structurally-assignable TypedDict)\n",
    "DatumMetadataType(TypedDict):\n",
    "    id: str|int\n",
    "\n",
    "InputType: TypeAlias = ArrayLike  # shape-(C, H, W) tensor with single image\n",
    "TargetType: TypeAlias = ArrayLike  # shape-(Cl) tensor of one-hot encoded true class or predicted probabilities\n",
    "\n",
    "InputBatchType: TypeAlias = Sequence[ArrayLike]  # element shape-(C, H, W) tensor of N images\n",
    "TargetBatchType: TypeAlias = Sequence[ArrayLike]  # element shape-(Cl,)\n",
    "DatumMetadataBatchType: TypeAlias = Sequence[DatumMetadataType]\n",
    "```\n",
    "\n",
    "Notes:\n",
    "\n",
    "* `TargetType` is used for both ground truth (coming from a dataset) and predictions (output from a model). So for a problem with 4 classes,\n",
    "\n",
    "  * true label of class 2 would be one-hot encoded as `[0, 0, 1, 0]`\n",
    "  * prediction from a model would be a vector of pseudo-probabilities, e.g., `[0.1, 0.0, 0.7, 0.2]`\n",
    "* `InputType` and `InputBatchType` are shown with shapes following PyTorch channels-first convention\n",
    "\n",
    "These type aliases along with the versions of the various component protocols that use these types can be imported from `maite.protocols.image_classification` (if necessary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import protocol classes\n",
    "from maite.protocols.image_classification import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    "    Model,\n",
    "    Augmentation,\n",
    "    Metric\n",
    ")\n",
    "\n",
    "# import type aliases\n",
    "from maite.protocols.image_classification import (\n",
    "    InputType,\n",
    "    TargetType,\n",
    "    DatumMetadataType,\n",
    "    InputBatchType,\n",
    "    TargetBatchType,\n",
    "    DatumMetadataBatchType\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, image classification components and types can be accessed via the module directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maite.protocols.image_classification as ic\n",
    "\n",
    "# model: ic.Model = load_model(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Object Detection\n",
    "\n",
    "For object detection with `D_i` detections in an image `i`, we have:\n",
    "\n",
    "```python\n",
    "# define type to store an id of each datum (additional fields can be added by defining structurally-assignable TypedDict)\n",
    "DatumMetadataType(TypedDict):\n",
    "    id: str|int\n",
    "\n",
    "class ObjectDetectionTarget(Protocol):\n",
    "    @property \n",
    "    def boxes(self) -> ArrayLike: ...  # shape-(D_i, 4) tensor of bounding boxes w/format X0, Y0, X1, Y1\n",
    "\n",
    "    @property\n",
    "    def labels(self) -> ArrayLike: ... # shape-(D_i) tensor of labels for each box\n",
    "\n",
    "    @property\n",
    "    def scores(self) -> ArrayLike: ... # shape-(D_i) tensor of scores for each box (e.g., probabilities)\n",
    "\n",
    "InputType: TypeAlias = ArrayLike  # shape-(C, H, W) tensor with single image\n",
    "TargetType: TypeAlias = ObjectDetectionTarget\n",
    "\n",
    "InputBatchType: TypeAlias = Sequence[ArrayLike]  # sequence of N ArrayLikes each of shape (C, H, W)\n",
    "TargetBatchType: TypeAlias = Sequence[TargetType]  # sequence of object detection \"target\" objects\n",
    "DatumMetadataBatchType: TypeAlias = Sequence[DatumMetadataType]\n",
    "```\n",
    "\n",
    "Notes:\n",
    "\n",
    "* `ObjectDetectionTarget` contains a single label and score per box\n",
    "* `InputType` and `InputBatchType` are shown with shapes following PyTorch channels-first convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Models\n",
    "\n",
    "All models implement a `__call__` method that takes the `InputBatchType` and produces the `TargetBatchType` appropriate for the given machine learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maite.protocols.image_classification as ic\n",
    "print(ic.Model.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maite.protocols.object_detection as od\n",
    "print(od.Model.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Datasets and DataLoaders\n",
    "\n",
    "`Dataset`s provide access to single data items and `DataLoader`s  provide access to batches of data with the input, target, and metadata types corresponding to the given machine learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ic.Dataset.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ic.DataLoader.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(od.DataLoader.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Augmentations\n",
    "\n",
    "`Augmentation`s take in and return a batch of data with the `InputBatchType`, `TargetBatchType`, and `DatumMetadataBatchType` types corresponding to the given machine learning task.\n",
    "\n",
    "Augmentations can access the datum-level metadata associated with each data item to potentially tailor the augmentation to individual items. Augmentations can also associate new datum-level metadata with each data item, e.g., documenting aspects of the actual change that was applied (e.g., the actual rotation angle sampled from a range of possible angles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ic.Augmentation.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(od.Augmentation.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Metrics\n",
    "\n",
    "The `Metric` protocol is inspired by the design of existing libraries like Torchmetrics and Torcheval. The `update` method operates on batches of predictions and truth labels by either caching them for later computation of the metric (via `compute`) or updating sufficient statistics in an online fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ic.Metric.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(od.Metric.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Workflows\n",
    "\n",
    "MAITE provides high-level utilities for common workflows such as `evaluate` and `predict`. They can be called with either `Dataset`s or `DataLoader`s, and with optional `Augmentation`.\n",
    "\n",
    "The `evaluate` function can optionally return the model predictions and (potentially-augmented) data batches used during inference.\n",
    "\n",
    "The `predict` function returns the model predictions and (potentially-augmented) data batches used during inference, essentially calling `evaluate` with a dummy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maite.workflows import evaluate, predict\n",
    "# we can also import from object_detection module\n",
    "# where the function call signature is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict.__doc__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
