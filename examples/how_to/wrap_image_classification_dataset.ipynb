{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2025, MASSACHUSETTS INSTITUTE OF TECHNOLOGY\n",
    "Subject to FAR 52.227-11 – Patent Rights – Ownership by the Contractor (May 2014).\n",
    "SPDX-License-Identifier: MIT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap an Image Classification Dataset\n",
    "\n",
    "In this how-to, we will show you how to wrap the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset as a [maite.protocols.image_classification.Dataset](../generated/maite.protocols.image_classification.Dataset.html). CIFAR-10 is an image classification dataset made by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.  It's available both through [Hugging Face Hub](https://huggingface.co/datasets/uoft-cs/cifar10) and [torchvision.datasets](https://pytorch.org/vision/main/generated/torchvision.datasets.CIFAR10.html), but this notebook uses Hugging Face Hub.\n",
    "\n",
    "The general steps for wrapping a dataset are:\n",
    "* Understand the source (native) dataset\n",
    "* Create a wrapper that makes the source dataset conform to the MAITE dataset protocol (interface)\n",
    "* Verify that the wrapped dataset works correctly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load the CIFAR-10 dataset from Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import datasets\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from IPython.display import display\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "import maite.protocols.image_classification as ic\n",
    "from maite.protocols import DatasetMetadata\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -iv -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CIFAR-10 dataset from Hugging Face Hub:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_dataset_dict = datasets.load_dataset(\"uoft-cs/cifar10\")\n",
    "cifar10_dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cifar10_dataset_dict` variable is a Hugging Face [datasets.DatasetDict](https://huggingface.co/docs/datasets/en/package_reference/main_classes#datasets.Dataset) object containing a 50000-image train dataset and a 10000-image test dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_train: datasets.Dataset = cifar10_dataset_dict[\"train\"] # type: ignore\n",
    "cifar10_test: datasets.Dataset = cifar10_dataset_dict[\"test\"] # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Examine the source dataset\n",
    "\n",
    "In this section we examine the dataset and confirm we understand it before wrapping it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the labels (class names) in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_number, label_name in enumerate(cifar10_train.features[\"label\"].names):\n",
    "    print(f\"Label {label_number}: {label_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot check the items in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(cifar10_train), 10000):\n",
    "    item = cifar10_train[i]\n",
    "    label, img = item[\"label\"], item[\"img\"]\n",
    "    label_name = cifar10_train.features[\"label\"].names[label]\n",
    "    print(f\"CIFAR-10 Train {i}\")\n",
    "    print(f\"Label: {label} {label_name}\")\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything appears as expected: CIFAR-10 images are 32x32 RGB and the labels correctly correspond to the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Create a MAITE wrapper for the source dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a class that implements the [maite.protocols.image_classification.Dataset](../generated/maite.protocols.image_classification.Dataset.html) protocol. \n",
    "\n",
    "\n",
    "A MAITE image classification compliant Dataset must include the following two methods:\n",
    "\n",
    "- `__getitem__(index: int)`: Returns a tuple containing the image `ArrayLike`, the target label, and the datum metadata.\n",
    "- `__len__()` : Returns the number of data elements in the dataset.   \n",
    "  \n",
    "and an attribute:\n",
    "\n",
    "- `metadata` containing an \"id\" string and an optional (but recommended) map from indexes to label.\n",
    "\n",
    "\n",
    "The `__getitem__` method is the most complex; it returns a tuple consisting of the image `ArrayLike`, the target label, and the datum metadata. The image [ArrayLike](../explanation/protocol_overview.html#concept-bridging-arraylikes) has the shape (channel, height, width). Both the `dtype` and value range of the image `ArrayLike` are not specified. You must be careful to ensure that users of the Dataset such as Augmentations or Models expect the provided `dtype` and values. The target label is a one-hot encoding of the label. The datum metadata is a dictionary that includes at least an `id`, of type `str` or `int`, for the datum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend DatasetMetadata to record whether dataset is a train or test split\n",
    "class CustomDatasetMetadata(DatasetMetadata):\n",
    "    split: str\n",
    "\n",
    "class Cifar10Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cifar10_dataset_split: datasets.Dataset,\n",
    "        split: Literal[\"train\", \"test\"]\n",
    "    ):\n",
    "        # Save the CIFAR-10 dataset given by the user. This is helpful if you want to\n",
    "        # sample the dataset using the Hugging Face API prior to using it.\n",
    "        self.dataset = cifar10_dataset_split\n",
    "\n",
    "        # Create a dictionary mapping label number to label name from the label metadata\n",
    "        # in the underlying dataset.\n",
    "        index2label = {\n",
    "            i: label for i, label in enumerate(self.dataset.features[\"label\"].names)\n",
    "        }\n",
    "\n",
    "        # Create required metadata attribute (with custom split key)\n",
    "        self.metadata: DatasetMetadata = CustomDatasetMetadata(\n",
    "            id=\"CIFAR-10\",\n",
    "            index2label=index2label,\n",
    "            split=split\n",
    "        )\n",
    "\n",
    "        # Get the number of classes used in the dataset\n",
    "        num_classes = self.dataset.features[\"label\"].num_classes\n",
    "\n",
    "        # Create a collection of target vectors to be used for the one-hot encoding of labels\n",
    "        self.targets = np.eye(num_classes)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(\n",
    "        self, index: int\n",
    "    ) -> tuple[npt.NDArray, npt.NDArray, ic.DatumMetadataType]:\n",
    "        # Look up item in the dataset, which returns a dictionary with two keys:\n",
    "        # - \"img\": PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
    "        # - \"label\": int\n",
    "        item = self.dataset[index]\n",
    "        img_pil = item[\"img\"]\n",
    "        label = item[\"label\"]\n",
    "\n",
    "        # Convert the PIL image to a NumPy array\n",
    "        img_hwc = np.array(img_pil)  # shape (H, W, C)\n",
    "\n",
    "        # Use MAITE array index convention for representing images: shape (C, H, W)\n",
    "        img_chw = img_hwc.transpose(2, 0, 1)\n",
    "\n",
    "        # Get one-hot encoded tensor indicating the class label for this image\n",
    "        target = self.targets[label, :].copy()\n",
    "\n",
    "        # CIFAR-10 does not have any extra metadata, so we record only the index of this datum\n",
    "        metadata: ic.DatumMetadataType = {\"id\": index}\n",
    "\n",
    "        return img_chw, target, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Examine the MAITE-wrapped dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the train dataset and print the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset: ic.Dataset = Cifar10Dataset(cifar10_dataset_split=cifar10_train, split=\"train\")\n",
    "train_dataset.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test dataset using the `test` split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset: ic.Dataset = Cifar10Dataset(cifar10_dataset_split=cifar10_test, split=\"test\")\n",
    "test_dataset.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the length of the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CIFAR-10 size: train={len(train_dataset)}, test={len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine some of the data points in the wrapped dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_datum(dataset, index):\n",
    "    img_arr_chw, target, datum_metadata = dataset[index]\n",
    "    print(f\"Datum {datum_metadata['id']}\")\n",
    "    print(f\"  Input Image Array: {str(img_arr_chw)[:30]}...\")\n",
    "    print(f\"    shape={img_arr_chw.shape}\")\n",
    "    print(f\"    dtype={img_arr_chw.dtype}\")\n",
    "    display(PIL.Image.fromarray(img_arr_chw.transpose(1, 2, 0)))\n",
    "    print(f\"  Target: {target}\")\n",
    "    label_index = np.argmax(target)\n",
    "    print(f\"    target index: {np.argmax(target)}\")\n",
    "    print(f\"    target label: {dataset.metadata['index2label'][label_index]}\")\n",
    "    print(\"  Metadata:\")\n",
    "    print(f\"    {datum_metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 3000, 6000]:\n",
    "    print_datum(test_dataset, i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Conclusion\n",
    "\n",
    "We've successfully wrapped the source CIFAR-10 dataset as a MAITE-compliant image classification dataset. Note that:\n",
    "\n",
    "* We don't observe any static type checking errors (assuming we've enabled static type checking in our IDE, e.g., by following the steps in the [Enable Static Type Checking](./static_typing.html) guide).\n",
    "* The wrapped dataset appears to be working correctly, e.g., image, ground truth target label, and metadata are consistent.\n",
    "\n",
    "At this point, the wrapped dataset could be used as part of a larger test & evaluation workflow, e.g., by using MAITE's [evaluate](../generated/maite.workflows.evaluate.html) workflow to compute the accuracy of a model on the CIFAR-10 test split."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i626_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
