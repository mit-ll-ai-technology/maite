{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of MAITE Protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAITE provides protocols for the following AI components:\n",
    "\n",
    "* models\n",
    "* datasets\n",
    "* dataloaders\n",
    "* augmentations\n",
    "* metrics\n",
    "\n",
    " MAITE protocols specify expected interfaces of these components (i.e, a minimal set of required attributes, methods, and method type signatures) to promote interoperability in test and evaluation (T&E). This enables the creation of higher-level workflows (e.g., an `evaluate` utility) that can interact with any components that conform to the protocols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Concept: Bridging ArrayLikes\n",
    "\n",
    "MAITE defines a protocol called `ArrayLike` (inspired by NumPy's [interoperability approach](https://numpy.org/devdocs/user/basics.interoperability.html)) that helps components that natively use different flavors of tensors (e.g., NumPy ndarray, PyTorch Tensor, JAX ndarray) work together.\n",
    "\n",
    "In this example, the functions \"type narrow\" from `ArrayLike` to the type they want to work with internally. Note that this doesn't necessarily require a conversion depending on the actual input type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from maite.protocols import ArrayLike\n",
    "\n",
    "def my_numpy_fn(x: ArrayLike) -> np.ndarray:\n",
    "    arr = np.asarray(x)\n",
    "    # ...\n",
    "    return arr\n",
    "\n",
    "def my_torch_fn(x: ArrayLike) -> torch.Tensor:\n",
    "    tensor = torch.as_tensor(x)\n",
    "    # ...\n",
    "    return tensor\n",
    "\n",
    "# can apply NumPy function to PyTorch Tensor\n",
    "np_out = my_numpy_fn(torch.rand(2, 3))\n",
    "\n",
    "# can apply PyTorch function to NumPy array\n",
    "torch_out = my_torch_fn(np.random.rand(2, 3))\n",
    "\n",
    "# note: no performance hit from conversion when all `ArrayLike`s are from same library\n",
    "# or when can share the same underlying memory\n",
    "torch_out = my_torch_fn(torch.rand(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using bridging, we MAITE can permit implementers of the protocol to internally interact with their own types while exposing a more open interface to other MAITE-compliant components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Types\n",
    "\n",
    "MAITE represents an *individual* data item as a tuple of:\n",
    "\n",
    "* input (i.e., image),\n",
    "* target (i.e., label), and\n",
    "* metadata (at the datum level)\n",
    "\n",
    "and a *batch* of data items as a tuple of:\n",
    "\n",
    "* input batches,\n",
    "* target batches, and\n",
    "* metadata batches.\n",
    "\n",
    "MAITE provides versions of `Model`, `Dataset`, `DataLoader`, `Augmentation`, and `Metric` protocols that correspond to different machine learning tasks (e.g. image classification, object detection) by parameterizing protocol interfaces on the particular input, target, and metadata types associated with that task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Image Classification\n",
    "\n",
    "For image classification with `Cl` image classes, we have:\n",
    "\n",
    "```python\n",
    "InputType: TypeAlias = ArrayLike  # shape-(C, H, W) tensor with single image\n",
    "TargetType: TypeAlias = ArrayLike  # shape-(Cl) tensor of one-hot encoded true class or predicted probabilities\n",
    "DatumMetadataType: TypeAlias = Dict[str, Any]\n",
    "\n",
    "InputBatchType: TypeAlias = ArrayLike  # shape-(N, C, H, W) tensor of N images\n",
    "TargetBatchType: TypeAlias = ArrayLike  # shape-(N, Cl)\n",
    "DatumMetadataBatchType: TypeAlias = Sequence[DatumMetadataType]\n",
    "```\n",
    "\n",
    "Notes:\n",
    "* `TargetType` is used for both ground truth (coming from a dataset) and predictions (output from a model). So for a problem with 4 classes,\n",
    "  * true label of class 2 would be one-hot encoded as `[0, 0, 1, 0]`\n",
    "  * prediction from a model would be a vector of pseudo-probabilities, e.g., `[0.1, 0.0, 0.7, 0.2]`\n",
    "* `InputBatchType` and `TargetBatchType` require all elements in the batch to be the same size (either natively or after resizing).\n",
    "* `InputType` and `InputBatchType` are shown with shapes following PyTorch channels-first convention\n",
    "\n",
    "These type aliases along with the versions of the various component protocols that use these types can be imported from `maite.protocols.image_classification` (if necessary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maite.protocols.image_classification import (\n",
    "    # - protocol classes -\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    "    Model,\n",
    "    Augmentation,\n",
    "    Metric,\n",
    "    # - type aliases -\n",
    "    InputType,\n",
    "    TargetType,\n",
    "    DatumMetadataType,\n",
    "    InputBatchType,\n",
    "    TargetBatchType,\n",
    "    DatumMetadataBatchType\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, image classification components and types can be accessed via the module directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maite.protocols.image_classification as ic\n",
    "\n",
    "# model: ic.Model = load_model(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Object Detection\n",
    "\n",
    "For object detection with `D_i` detections in an image `i`, we have:\n",
    "\n",
    "```python\n",
    "class ObjectDetectionTarget(Protocol):\n",
    "    @property \n",
    "    def boxes(self) -> ArrayLike: ...  # shape-(D_i, 4) tensor of bounding boxes w/format X0, Y0, X1, Y1\n",
    "\n",
    "    @property\n",
    "    def labels(self) -> ArrayLike: ... # shape-(D_i) tensor of labels for each box\n",
    "\n",
    "    @property\n",
    "    def scores(self) -> ArrayLike: ... # shape-(D_i) tensor of scores for each box (e.g., probabilities)\n",
    "\n",
    "InputType: TypeAlias = ArrayLike  # shape-(C, H, W) tensor with single image\n",
    "TargetType: TypeAlias = ObjectDetectionTarget\n",
    "DatumMetadataType: TypeAlias = Dict[str, Any]\n",
    "\n",
    "InputBatchType: TypeAlias = ArrayLike  # shape-(N, C, H, W) tensor of N images\n",
    "TargetBatchType: TypeAlias = Sequence[TargetType]  # length N\n",
    "DatumMetadataBatchType: TypeAlias = Sequence[DatumMetadataType]\n",
    "```\n",
    "\n",
    "Notes:\n",
    "* `ObjectDetectionTarget` contains a single label and score per box\n",
    "* `TargetBatchType` requires all inputs in the batch to be the same size or have been resized to the same size\n",
    "* `InputType` and `InputBatchType` are shown with shapes following PyTorch channels-first convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Models\n",
    "\n",
    "All models implement a `__call__` method that takes the `InputBatchType` and produces the `TargetBatchType` appropriate for the given machine learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    A model protocol for the image classification ML subproblem.\n",
      "\n",
      "    Implementers must provide a `__call__` method that operates on a batch of model\n",
      "    inputs (as `ArrayLike`s) and returns a batch of model targets (implementers of\n",
      "    `ArrayLike`)\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "\n",
      "    __call__(input_batch: ArrayLike)->ArrayLike\n",
      "        Make a model prediction for inputs in input batch. Input batch is expected in\n",
      "        the shape `(N, C, H, W)`.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import maite.protocols.image_classification as ic\n",
    "print(ic.Model.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    A model protocol for the object detection ML subproblem.\n",
      "\n",
      "    Implementers must provide a `__call__` method that operates on a batch of model inputs\n",
      "    (as `ArrayLike`s) and returns a batch of model targets (as\n",
      "    `Sequence[ObjectDetectionTarget]`)\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "\n",
      "    __call__(input_batch: ArrayLike)->Sequence[ObjectDetectionTarget]\n",
      "        Make a model prediction for inputs in input batch. Input batch is expected in\n",
      "        the shape `(N, C, H, W)`.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import maite.protocols.object_detection as od\n",
    "print(od.Model.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Datasets and DataLoaders\n",
    "\n",
    "`Dataset`s provide access to single data items and `DataLoader`s  provide access to batches of data with the input, target, and metadata types corresponding to the given machine learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    A dataset protocol for image classification ML subproblem providing datum-level\n",
      "    data access.\n",
      "\n",
      "    Implementers must provide index lookup (via `__getitem__(ind: int)` method) and\n",
      "    support `len` (via `__len__()` method). Data elements looked up this way correspond to\n",
      "    individual examples (as opposed to batches).\n",
      "\n",
      "    Indexing into or iterating over the an image_classification dataset returns a `Tuple` of\n",
      "    types `ArrayLike`, `ArrayLike`, and `Dict[str,Any]`. These correspond to\n",
      "    the model input type, model target type, and datum-level metadata, respectively.\n",
      "\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "\n",
      "    __getitem__(ind: int)->Tuple[ArrayLike, ArrayLike, Dict[str, Any]]\n",
      "        Provide mapping-style access to dataset elements. Returned tuple elements\n",
      "        correspond to model input type, model target type, and datum-specific metadata,\n",
      "        respectively.\n",
      "\n",
      "    __len__()->int\n",
      "        Return the number of data elements in the dataset.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(ic.Dataset.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    A dataloader protocol for the image classification ML subproblem providing\n",
      "    batch-level data access.\n",
      "\n",
      "    Implementers must provide an iterable object (returning an iterator via the\n",
      "    `__iter__` method) that yields tuples containing batches of data. These tuples\n",
      "    contain types `ArrayLike` (shape `(N, C, H, W)`), `ArrayLike` (shape `(N, Cl)`),\n",
      "    and `Sequence[Dict[str, Any]]`, which correspond to model input batch, model target\n",
      "    type batch, and a datum metadata batch.\n",
      "\n",
      "    Note: Unlike Dataset, this protocol does not require indexing support, only iterating.\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "\n",
      "    __iter__->Iterator[tuple[ArrayLike, ArrayLike, Sequence[Dict[str, Any]]]]\n",
      "        Return an iterator over batches of data, where each batch contains a tuple of\n",
      "        of model input batch (as an `ArrayLike`), model target batch (as\n",
      "        an `ArrayLike`), and batched datum-level metadata\n",
      "        (as `Sequence[Dict[str,Any]]`), respectively.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(ic.DataLoader.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    A dataloader protocol for the object detection ML subproblem providing\n",
      "    batch-level data access.\n",
      "\n",
      "    Implementers must provide an iterable object (returning an iterator via the\n",
      "    `__iter__` method) that yields tuples containing batches of data. These tuples\n",
      "    contain types `ArrayLike` (shape `(N, C, H, W)`), `Sequence[ObjectDetectionTarget]`,\n",
      "    `Sequence[Dict[str, Any]]`, which correspond to model input batch, model target\n",
      "    type batch, and datum metadata batch.\n",
      "\n",
      "    Note: Unlike Dataset, this protocol does not require indexing support, only iterating.\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "\n",
      "    __iter__->Iterator[tuple[ArrayLike, Sequence[ObjectDetectionTarget], Sequence[Dict[str, Any]]]]\n",
      "        Return an iterator over batches of data, where each batch contains a tuple of\n",
      "        of model input batch (as an `ArrayLike`), model target batch (as\n",
      "        `Sequence[ObjectDetectionTarget]`), and batched datum-level metadata\n",
      "        (as `Sequence[Dict[str,Any]]`), respectively.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(od.DataLoader.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Augmentations\n",
    "\n",
    "`Augmentation`s take in and return a batch of data with the `InputBatchType`, `TargetBatchType`, and `DatumMetadataBatchType` types corresponding to the given machine learning task.\n",
    "\n",
    "Augmentations can access the datum-level metadata associated with each data item to potentially tailor the augmentation to individual items. Augmentations can also associate new datum-level metadata with each data item, e.g., documenting aspects of the actual change that was applied (e.g., the actual rotation angle sampled from a range of possible angles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    An augmentation protocol for the image classification subproblem.\n",
      "\n",
      "    An augmentation is expected to take a batch of data and return a modified version of\n",
      "    that batch. Implementers must provide a single method that takes and returns a\n",
      "    labeled data batch, where a labeled data batch is represented by a tuple of types\n",
      "    `ArrayLike` (of shape `(N, C, H, W)`), `ArrayLike` (of shape `(N, Cl)`), and\n",
      "    `Sequence[Dict[str,Any]]`. These correspond to the model input batch type, model\n",
      "    target batch type, and datum-level metadata batch type, respectively.\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "\n",
      "    __call__(datum: Tuple[ArrayLike, ArrayLike, Sequence[dict[str, Any]]])->\n",
      "                Tuple[ArrayLike, ArrayLike, Sequence[dict[str, Any]]]\n",
      "        Return a modified version of original data batch. A data batch is represented\n",
      "        by a tuple of model input batch (as an `ArrayLike` of shape `(N, C, H, W)`),\n",
      "        model target batch (as an `ArrayLike` of shape `(N, Cl)`), and batch metadata (as\n",
      "        `Sequence[Dict[str,Any]]`), respectively.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(ic.Augmentation.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    An augmentation protocol for the object detection subproblem.\n",
      "\n",
      "    An augmentation is expected to take a batch of data and return a modified version of\n",
      "    that batch. Implementers must provide a single method that takes and returns a\n",
      "    labeled data batch, where a labeled data batch is represented by a tuple of types\n",
      "    `ArrayLike`, `Sequence[ObjectDetectionTarget]`, and `Sequence[Dict[str,Any]]`. These\n",
      "    correspond to the model input batch type, model target batch type, and datum-level\n",
      "    metadata batch type, respectively.\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "\n",
      "    __call__(datum: Tuple[ArrayLike, Sequence[ObjectDetectionTarget, dict[str, Any]]])->\n",
      "                Tuple[ArrayLike, Sequence[ObjectDetectionTarget], Sequence[dict[str, Any]]]\n",
      "        Return a modified version of original data batch. A data batch is represented\n",
      "        by a tuple of model input batch (as an `ArrayLike` of shape `(N, C, H, W)`),\n",
      "        model target batch (as `Sequence[ObjectDetectionTarget]`), and batch metadata\n",
      "        (as `Sequence[Dict[str,Any]]`), respectively.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(od.Augmentation.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Metrics\n",
    "\n",
    "The `Metric` protocol is inspired by the design of existing libraries like Torchmetrics and Torcheval. The `update` method operates on batches of predictions and truth labels by either caching them for later computation of the metric (via `compute`) or updating sufficient statistics in an online fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    A metric protocol for the image classification ML subproblem.\n",
      "\n",
      "    A metric in this sense is expected to measure the level of agreement between model\n",
      "    predictions and ground-truth labels.\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "\n",
      "    update(preds: ArrayLike, targets: ArrayLike)->None\n",
      "        Add predictions and targets to metric's cache for later calculation. Both\n",
      "        preds and targets are expected to be of shape `(N, Cl)`.\n",
      "\n",
      "    compute()->Dict[str, Any]\n",
      "        Compute metric value(s) for currently cached predictions and targets, returned as\n",
      "        a dictionary.\n",
      "\n",
      "    reset()->None\n",
      "        Clear contents of current metric's cache of predictions and targets.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(ic.Metric.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    A metric protocol for the object detection ML subproblem.\n",
      "\n",
      "     A metric in this sense is expected to measure the level of agreement between model\n",
      "     predictions and ground-truth labels.\n",
      "\n",
      "     Methods\n",
      "     -------\n",
      "\n",
      "     update(preds: Sequence[ObjectDetectionTarget], targets: Sequence[ObjectDetectionTarget])->None\n",
      "         Add predictions and targets to metric's cache for later calculation.\n",
      "\n",
      "     compute()->Dict[str, Any]\n",
      "         Compute metric value(s) for currently cached predictions and targets, returned as\n",
      "         a dictionary.\n",
      "\n",
      "     reset()->None\n",
      "         Clear contents of current metric's cache of predictions and targets.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(od.Metric.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Workflows\n",
    "\n",
    "MAITE provides high-level utilities for common workflows such as `evaluate` and `predict`. They can be called with either `Dataset`s or `DataLoader`s, and with optional `Augmentation`.\n",
    "\n",
    "The `evaluate` function can optionally return the model predictions and (potentially-augmented) data batches used during inference.\n",
    "\n",
    "The `predict` function returns the model predictions and (potentially-augmented) data batches used during inference, essentially calling `evaluate` with a dummy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maite.workflows import evaluate, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Evaluate a model's performance on data according to some metric with optional augmentation.\n",
      "\n",
      "    Some data source (either a dataloader or a dataset) must be provided\n",
      "    or an InvalidArgument exception is raised.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    model : SomeModel\n",
      "        Maite Model object.\n",
      "\n",
      "    metric : Optional[SomeMetric], (default=None)\n",
      "        Compatible maite Metric.\n",
      "\n",
      "    dataset : Optional[SomeDataset], (default=None)\n",
      "        Compatible maite dataset.\n",
      "\n",
      "    batch_size : int, (default=1)\n",
      "        Batch size for use with dataset (ignored if dataset=None).\n",
      "\n",
      "    dataloader : Optional[SomeDataloader], (default=None)\n",
      "        Compatible maite dataloader.\n",
      "\n",
      "    augmentation : Optional[SomeAugmentation], (default=None)\n",
      "        Compatible maite augmentation.\n",
      "\n",
      "    return_augmented_data : bool, (default=False)\n",
      "        Set to True to return post-augmentation data as a function output.\n",
      "\n",
      "    return_preds : bool, (default=False)\n",
      "        Set to True to return raw predictions as a function output.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    Tuple[Dict[str, Any], Sequence[TargetType], Sequence[Tuple[InputBatchType, TargetBatchType, DatumMetadataBatchType]]]\n",
      "        Tuple of returned metric value, sequence of model predictions, and\n",
      "        sequence of data batch tuples fed to the model during inference. The actual\n",
      "        types represented by InputBatchType, TargetBatchType, and DatumMetadataBatchType will vary\n",
      "        by the domain of the components provided as input arguments (e.g. image\n",
      "        classification or object detection.)\n",
      "        Note that the second and third return arguments will be empty if\n",
      "        return_augmented_data is False or return_preds is False, respectively.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(evaluate.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Make predictions for a given model & data source with optional augmentation.\n",
      "\n",
      "    Some data source (either a dataloader or a dataset) must be provided\n",
      "    or an InvalidArgument exception is raised.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    model : SomeModel\n",
      "        Maite Model object.\n",
      "\n",
      "    dataloader : Optional[SomeDataloader], (default=None)\n",
      "        Compatible maite dataloader.\n",
      "\n",
      "    dataset : Optional[SomeDataset], (default=None)\n",
      "        Compatible maite dataset.\n",
      "\n",
      "    batch_size : int, (default=1)\n",
      "        Batch size for use with dataset (ignored if dataset=None).\n",
      "\n",
      "    augmentation : Optional[SomeAugmentation], (default=None)\n",
      "        Compatible maite augmentation.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    Tuple[Sequence[SomeTargetBatchType], Sequence[Tuple[SomeInputBatchType, SomeTargetBatchType, SomeMetadataBatchType]],\n",
      "        A tuple of the predictions (as a sequence of batches) and a sequence\n",
      "        of tuples containing the information associated with each batch.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(predict.__doc__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maite_mwe3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
